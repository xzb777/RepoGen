{
    "implementation": [
        {
            "key_id": 0,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/__init__",
            "imports": [
                "import numpy as np"
            ],
            "code": "class ConstrainedLinearRegression:\n    def __init__(self, fit_intercept: bool = True, alpha: float = 0.0):\n        self.fit_intercept = fit_intercept\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = 0.0\n        self.is_fitted_ = False\n\n        # Placeholder for internal optimizer solution\n        self._optimizer_result = None"
        },
        {
            "key_id": 4,
            "fqn": "constrainedlr/validation.py/validate_constraint_features_all_strings_or_all_int",
            "imports": [],
            "code": "def validate_constraint_features_all_strings_or_all_int(constraints: dict) -> None:\n    if not all(isinstance(key, str) for key in constraints) and not all(isinstance(key, int) for key in constraints):\n        raise ValueError('All constraint feature keys must be all strings or all integers.')"
        },
        {
            "key_id": 5,
            "fqn": "constrainedlr/validation.py/get_clean_feature_names_from_pipeline",
            "imports": [],
            "code": "def get_clean_feature_names_from_pipeline(feature_names: list[str]) -> list[str]:\n    return [name.strip() for name in feature_names]"
        },
        {
            "key_id": 6,
            "fqn": "constrainedlr/validation.py/validate_feature_names_in_constraints",
            "imports": [],
            "code": "def validate_feature_names_in_constraints(constraints: dict, feature_names: list[str]) -> None:\n    if not all(name in feature_names for name in constraints.keys()):\n        raise ValueError('All constraint feature names must exist in the provided feature names.')"
        },
        {
            "key_id": 7,
            "fqn": "constrainedlr/validation.py/convert_feature_names_to_indices",
            "imports": [
                "numpy as np"
            ],
            "code": "def convert_feature_names_to_indices(constraints: dict, feature_names_in_: np.ndarray[str]) -> dict:\n    feature_names_list = feature_names_in_.tolist()\n    return {feature_names_list.index(key) if isinstance(key, str) else key: value for key, value in constraints.items()}"
        },
        {
            "key_id": 8,
            "fqn": "constrainedlr/validation.py/validate_coefficients_sign_constraints",
            "imports": [],
            "code": "def validate_coefficients_sign_constraints(coefficients_sign_constraints: Optional[dict], X: Union[np.ndarray, pd.DataFrame], feature_names_in_: Optional[np.ndarray[str]]) -> dict:\n    if coefficients_sign_constraints is None:\n        return {}\n    validated_constraints = {}\n    for key, value in coefficients_sign_constraints.items():\n        if value not in ['positive', 'negative']:\n            raise ValueError('Coefficient sign constraints must be either \"positive\" or \"negative\".')\n        if isinstance(key, str):\n            key = np.where(feature_names_in_ == key)[0][0]\n        validated_constraints[key] = value\n    return validated_constraints"
        },
        {
            "key_id": 9,
            "fqn": "constrainedlr/validation.py/validate_intercept_sign_constraint",
            "imports": [
                "from typing import Union"
            ],
            "code": "def validate_intercept_sign_constraint(intercept_sign_constraint: Union[int, str]) -> int:\n    if isinstance(intercept_sign_constraint, str):\n        if intercept_sign_constraint.lower() == 'positive':\n            return 1\n        elif intercept_sign_constraint.lower() == 'negative':\n            return -1\n        else:\n            raise ValueError('Invalid value for intercept_sign_constraint. Allowed values are \"positive\", \"negative\", or an integer.')\n    elif isinstance(intercept_sign_constraint, int):\n        return intercept_sign_constraint\n    else:\n        raise TypeError('intercept_sign_constraint must be either a string (\"positive\" or \"negative\") or an integer.')"
        },
        {
            "key_id": 10,
            "fqn": "constrainedlr/validation.py/validate_coefficients_range_constraints",
            "imports": [
                "from typing import Optional, Union, dict",
                "import numpy as np",
                "from .validate_constraint_features_all_strings_or_all_int import validate_constraint_features_all_strings_or_all_int",
                "from .convert_feature_names_to_indices import convert_feature_names_to_indices"
            ],
            "code": "def validate_coefficients_range_constraints(coefficients_range_constraints: Optional[dict], X: Union[np.ndarray, pd.DataFrame], feature_names_in_: Optional[np.ndarray[str]]) -> dict:\n    if not coefficients_range_constraints:\n        return {}\n    validate_constraint_features_all_strings_or_all_int(coefficients_range_constraints)\n    constraints_indices = convert_feature_names_to_indices(coefficients_range_constraints, feature_names_in_)\n    for key, value in constraints_indices.items():\n        if 'lower' in value and 'upper' in value:\n            if value['lower'] > value['upper']:\n                raise ValueError(f'Lower bound cannot be greater than upper bound for feature {key}.')\n    return constraints_indices"
        },
        {
            "key_id": 1,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/fit",
            "imports": [
                "from typing import Union, Optional",
                "import numpy as np",
                "from sklearn.base import BaseEstimator",
                "from .validation import validate_coefficients_sign_constraints, validate_intercept_sign_constraint, validate_coefficients_range_constraints"
            ],
            "code": "class ConstrainedLinearRegression(BaseEstimator):\n    def __init__(self, fit_intercept: bool = True, alpha: float = 0.0):\n        self.fit_intercept = fit_intercept\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = 0.0\n        self.is_fitted_ = False\n        self._optimizer_result = None\n\n    def fit(self, X: Union[np.ndarray, pd.DataFrame], y: np.ndarray, sample_weight: Optional[np.ndarray] = None, coefficients_sign_constraints: Optional[dict] = None, coefficients_range_constraints: Optional[dict] = None, intercept_sign_constraint: Union[int, str] = 0, coefficients_sum_constraint: Optional[float] = None) -> \"ConstrainedLinearRegression\":\n        # This is a placeholder for the actual implementation logic, including validation and optimization steps\n        return self"
        },
        {
            "key_id": 2,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/predict",
            "imports": [
                "import numpy as np"
            ],
            "code": "class ConstrainedLinearRegression:\n    def predict(self, X: Union[np.ndarray, pd.DataFrame]) -> np.ndarray:\n        if not self.is_fitted_:\n            raise ValueError('This ConstrainedLinearRegression instance is not fitted yet.')\n        # Placeholder for prediction logic\n        return np.dot(X, self.coef_) + self.intercept_"
        },
        {
            "key_id": 3,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/get_feature_names_out",
            "imports": [],
            "code": "class ConstrainedLinearRegression:\n    def get_feature_names_out(self) -> np.ndarray[str]:\n        if not self.is_fitted_:\n            raise ValueError('This ConstrainedLinearRegression instance is not fitted yet.')\n        # Assuming feature names are simply column indices for simplicity\n        return np.array([str(i) for i in range(self.coef_.shape[0])])"
        }
    ]
}