{
    "implementation": [
        {
            "key_id": 0,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__init__",
            "imports": [
                "import logging",
                "from typing import Optional, Callable",
                "from uuid import UUID"
            ],
            "code": "def __init__(self, dsn: str, queue_name: str, table_name: str = 'task_queue', reset: bool = False, create_table: bool = False, ttl_zero_callback: Optional[Callable[[UUID, Optional[str]], None]] = None):\n    self.dsn = dsn\n    self.queue_name = queue_name\n    self.table_name = table_name\n    self.reset = reset\n    self.create_table = create_table\n    self.ttl_zero_callback = ttl_zero_callback\n    self.logger = logging.getLogger(__name__)\n    if self.create_table:\n        self._create_queue_table()\n    if self.reset:\n        self._reset()\n    self.connect()"
        },
        {
            "key_id": 1,
            "fqn": "postgrestq/task_queue.py/TaskQueue/connect",
            "imports": [
                "import psycopg",
                "import logging"
            ],
            "code": "def connect(self) -> None:\n    try:\n        self.conn = psycopg.connect(self.dsn)\n        self.cur = self.conn.cursor()\n        self.logger.info('Successfully connected to the database.')\n    except Exception as e:\n        self.logger.error('Failed to connect to the database.', exc_info=e)\n        raise"
        },
        {
            "key_id": 2,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
            "imports": [
                "import psycopg"
            ],
            "code": "def _create_queue_table(self) -> None:\n    create_table_query = f\"\"\"CREATE TABLE IF NOT EXISTS {self.table_name} (\n        id UUID PRIMARY KEY,\n        queue_name TEXT NOT NULL,\n        task JSONB NOT NULL,\n        ttl INT NOT NULL,\n        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n        processing BOOLEAN NOT NULL DEFAULT false,\n        lease_timeout FLOAT,\n        deadline TIMESTAMP,\n        completed_at TIMESTAMP\n    )\"\"\"\n    try:\n        self.cur.execute(create_table_query)\n        self.conn.commit()\n        self.logger.info(f'Table {self.table_name} created successfully.')\n    except Exception as e:\n        self.logger.error(f'Failed to create table {self.table_name}.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 13,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_reset",
            "imports": [
                "import psycopg"
            ],
            "code": "def _reset(self) -> None:\n    reset_query = f'DELETE FROM {self.table_name} WHERE queue_name = %s'\n    try:\n        self.cur.execute(reset_query, (self.queue_name,))\n        self.conn.commit()\n        self.logger.info(f'Queue {self.queue_name} has been reset.')\n    except Exception as e:\n        self.logger.error(f'Failed to reset queue {self.queue_name}.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 1,
            "fqn": "postgrestq/task_queue.py/TaskQueue/connect",
            "imports": [
                "import psycopg",
                "import logging"
            ],
            "code": "def connect(self) -> None:\n    try:\n        self.conn = psycopg.connect(self.dsn)\n        self.cur = self.conn.cursor()\n        self.logger.info('Successfully connected to the database.')\n    except Exception as e:\n        self.logger.error('Failed to connect to the database.', exc_info=e)"
        },
        {
            "key_id": 2,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
            "imports": [
                "import logging"
            ],
            "code": "def _create_queue_table(self) -> None:\n    create_table_query = '''\n    CREATE TABLE IF NOT EXISTS task_queue (\n        id UUID PRIMARY KEY,\n        queue_name TEXT NOT NULL,\n        task JSONB NOT NULL,\n        ttl INT NOT NULL,\n        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n        processing BOOLEAN NOT NULL DEFAULT false,\n        lease_timeout FLOAT,\n        deadline TIMESTAMP,\n        completed_at TIMESTAMP\n    )'''\n    try:\n        self.cur.execute(create_table_query)\n        self.conn.commit()\n        self.logger.info('Table task_queue successfully created.')\n    except Exception as e:\n        self.logger.error('Failed to create table task_queue.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 10,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_serialize",
            "imports": [
                "import json",
                "import logging"
            ],
            "code": "def _serialize(self, task: Any) -> str:\n    try:\n        return json.dumps(task)\n    except TypeError as e:\n        self.logger.error('Failed to serialize task.', exc_info=e)\n        raise"
        },
        {
            "key_id": 11,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_deserialize",
            "imports": [
                "import json",
                "import logging"
            ],
            "code": "def _deserialize(self, blob: str) -> Any:\n    try:\n        return json.loads(blob)\n    except json.JSONDecodeError as e:\n        self.logger.error('Failed to deserialize task.', exc_info=e)\n        raise"
        },
        {
            "key_id": 13,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_reset",
            "imports": [
                "import logging"
            ],
            "code": "def _reset(self) -> None:\n    reset_query = f'DELETE FROM {self.table_name} WHERE queue_name = %s'\n    try:\n        self.cur.execute(reset_query, (self.queue_name,))\n        self.conn.commit()\n        self.logger.info(f'Queue {self.queue_name} has been reset.')\n    except Exception as e:\n        self.logger.error(f'Failed to reset queue {self.queue_name}.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 4,
            "fqn": "postgrestq/task_queue.py/TaskQueue/add",
            "imports": [
                "import logging",
                "from uuid import uuid4",
                "import json",
                "import psycopg"
            ],
            "code": "def add(self, task: Dict[str, Any], lease_timeout: float, ttl: int = 3) -> str:\n    task_id = str(uuid4())\n    serialized_task = json.dumps(task)\n    insert_query = f'INSERT INTO {self.table_name} (id, queue_name, task, ttl, lease_timeout, processing) VALUES (%s, %s, %s, %s, %s, %s)'\n    try:\n        self.cur.execute(insert_query, (task_id, self.queue_name, serialized_task, ttl, lease_timeout, False))\n        self.conn.commit()\n        logger.info(f'Task {task_id} added to queue {self.queue_name}.')\n    except Exception as e:\n        logger.error(f'Failed to add task to queue {self.queue_name}.', exc_info=e)\n        self.conn.rollback()\n    return task_id"
        },
        {
            "key_id": 9,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get_updated_expired_task",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:\n    select_query = f'SELECT task, ttl FROM {self.table_name} WHERE id = %s'\n    self.cur.execute(select_query, (str(task_id),))\n    result = self.cur.fetchone()\n    if result:\n        task, ttl = result\n        return (task, ttl)\n    else:\n        logger.warning(f'Task {task_id} not found or already processed.')\n        return (None, None)"
        },
        {
            "key_id": 8,
            "fqn": "postgrestq/task_queue.py/TaskQueue/check_expired_leases",
            "imports": [
                "import logging",
                "import psycopg",
                "from datetime import datetime, timedelta"
            ],
            "code": "def check_expired_leases(self) -> None:\n    now = datetime.now()\n    update_query = f'UPDATE {self.table_name} SET processing = FALSE, completed_at = NULL WHERE deadline < %s AND processing = TRUE AND queue_name = %s'\n    try:\n        self.cur.execute(update_query, (now, self.queue_name))\n        self.conn.commit()\n        affected_rows = self.cur.rowcount\n        logger.info(f'{affected_rows} tasks leases expired and reset in queue {self.queue_name}.')\n    except Exception as e:\n        logger.error(f'Failed to check and reset expired leases in queue {self.queue_name}.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 7,
            "fqn": "postgrestq/task_queue.py/TaskQueue/is_empty",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def is_empty(self) -> bool:\n    select_query = f'SELECT COUNT(*) FROM {self.table_name} WHERE queue_name = %s AND completed_at IS NULL'\n    self.cur.execute(select_query, (self.queue_name,))\n    count = self.cur.fetchone()[0]\n    return count == 0"
        },
        {
            "key_id": 15,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__iter__",
            "imports": [
                "import logging",
                "import psycopg",
                "from typing import Iterator, Tuple, Optional",
                "from uuid import UUID",
                "import json"
            ],
            "code": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:\n    while not self.is_empty():\n        task, task_id = self.get()\n        if task is not None:\n            yield task, task_id\n            self.complete(task_id)"
        },
        {
            "key_id": 5,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get",
            "imports": [
                "import logging",
                "from typing import Tuple, Optional, Dict",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def get(self) -> Tuple[Optional[Dict[str, Any]], Optional[UUID]]:\n    logger = logging.getLogger(__name__)\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"\"\"UPDATE task_queue SET processing = true, deadline = current_timestamp + CAST(lease_timeout || ' seconds' AS INTERVAL) WHERE id = (SELECT id FROM task_queue WHERE completed_at IS NULL AND processing = false AND queue_name = %s AND ttl > 0 ORDER BY created_at FOR UPDATE SKIP LOCKED LIMIT 1) RETURNING id, task\"\"\",\n                (self.queue_name,)\n            )\n            result = cur.fetchone()\n            self.conn.commit()\n            if result:\n                return self._deserialize(result[1]), result[0]\n            else:\n                return None, None\n    except Exception as e:\n        logger.error('Failed to get task from queue.', exc_info=e)\n        self.conn.rollback()\n        return None, None"
        },
        {
            "key_id": 6,
            "fqn": "postgrestq/task_queue.py/TaskQueue/complete",
            "imports": [
                "import logging",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def complete(self, task_id: Optional[UUID]) -> None:\n    logger = logging.getLogger(__name__)\n    if task_id is None:\n        logger.error('Task ID is None, cannot mark task as complete.')\n        return\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"\"\"UPDATE task_queue SET completed_at = current_timestamp WHERE id = %s\"\"\",\n                (task_id,)\n            )\n            self.conn.commit()\n            logger.info(f'Task {task_id} marked as complete.')\n    except Exception as e:\n        logger.error(f'Failed to mark task {task_id} as complete.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 12,
            "fqn": "postgrestq/task_queue.py/TaskQueue/reschedule",
            "imports": [
                "import logging",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def reschedule(self, task_id: Optional[UUID]) -> None:\n    logger = logging.getLogger(__name__)\n    if task_id is None:\n        logger.error('Task ID is None, cannot reschedule task.')\n        return\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"\"\"UPDATE task_queue SET processing = false, completed_at = NULL, deadline = NULL WHERE id = %s\"\"\",\n                (task_id,)\n            )\n            self.conn.commit()\n            logger.info(f'Task {task_id} has been rescheduled.')\n    except Exception as e:\n        logger.error(f'Failed to reschedule task {task_id}.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 14,
            "fqn": "postgrestq/task_queue.py/TaskQueue/prune_completed_tasks",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def prune_completed_tasks(self, before: int) -> None:\n    logger = logging.getLogger(__name__)\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"\"\"DELETE FROM task_queue WHERE completed_at < current_timestamp - INTERVAL '%s seconds'\"\"\",\n                (before,)\n            )\n            self.conn.commit()\n            logger.info(f'Pruned tasks completed more than {before} seconds ago.')\n    except Exception as e:\n        logger.error('Failed to prune completed tasks.', exc_info=e)\n        self.conn.rollback()"
        },
        {
            "key_id": 3,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__len__",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def __len__(self) -> int:\n    logger = logging.getLogger(__name__)\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"\"\"SELECT COUNT(*) FROM task_queue WHERE queue_name = %s AND completed_at IS NULL\"\"\",\n                (self.queue_name,)\n            )\n            count = cur.fetchone()[0]\n            return count\n    except Exception as e:\n        logger.error('Failed to get queue length.', exc_info=e)\n        self.conn.rollback()\n        return 0"
        }
    ]
}