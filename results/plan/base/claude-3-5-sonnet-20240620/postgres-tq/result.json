{
    "implementation": [
        {
            "key_id": 0,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__init__",
            "imports": [
                "import logging",
                "from typing import Optional, Callable, Dict, Any",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def __init__(self, dsn: str, queue_name: str, table_name: str = \"task_queue\", reset: bool = False, create_table: bool = False, ttl_zero_callback: Optional[Callable[[UUID, Optional[str]], None]] = None):\n    self.logger = logging.getLogger(__name__)\n    self.dsn = dsn\n    self.queue_name = queue_name\n    self.table_name = table_name\n    self.ttl_zero_callback = ttl_zero_callback\n    self.conn = None\n    self.connect()\n    if create_table:\n        self._create_queue_table()\n    if reset:\n        self._reset()\n    self.logger.info(f\"Initialized TaskQueue with queue_name: {queue_name}, table_name: {table_name}\")"
        },
        {
            "key_id": 1,
            "fqn": "postgrestq/task_queue.py/TaskQueue/connect",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def connect(self) -> None:\n    try:\n        self.conn = psycopg.connect(self.dsn)\n        self.logger.info(\"Successfully connected to the database.\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error connecting to the database: {e}\")\n        raise"
        },
        {
            "key_id": 2,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def _create_queue_table(self) -> None:\n    create_table_query = f\"\"\"\n    CREATE TABLE IF NOT EXISTS {self.table_name} (\n        id UUID PRIMARY KEY,\n        queue_name TEXT NOT NULL,\n        task JSONB NOT NULL,\n        ttl INT NOT NULL,\n        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n        processing BOOLEAN NOT NULL DEFAULT false,\n        lease_timeout FLOAT,\n        deadline TIMESTAMP,\n        completed_at TIMESTAMP\n    )\n    \"\"\"\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(create_table_query)\n        self.conn.commit()\n        self.logger.info(f\"Table '{self.table_name}' created successfully.\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error creating table: {e}\")\n        self.conn.rollback()\n        raise"
        },
        {
            "key_id": 3,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__len__",
            "imports": [
                "import logging",
                "import psycopg"
            ],
            "code": "def __len__(self) -> int:\n    query = f\"\"\"\n    SELECT COUNT(*)\n    FROM {self.table_name}\n    WHERE queue_name = %s AND completed_at IS NULL\n    \"\"\"\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(query, (self.queue_name,))\n            count = cur.fetchone()[0]\n        return count\n    except psycopg.Error as e:\n        self.logger.error(f\"Error getting queue length: {e}\")\n        raise"
        },
        {
            "key_id": 10,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_serialize",
            "imports": [
                "import json",
                "from typing import Any"
            ],
            "code": "def _serialize(self, task: Any) -> str:\n    try:\n        return json.dumps(task)\n    except (TypeError, ValueError) as e:\n        self.logger.error(f\"Error serializing task: {e}\")\n        raise"
        },
        {
            "key_id": 11,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_deserialize",
            "imports": [
                "import json",
                "from typing import Any"
            ],
            "code": "def _deserialize(self, blob: str) -> Any:\n    try:\n        return json.loads(blob)\n    except json.JSONDecodeError as e:\n        self.logger.error(f\"Error deserializing task: {e}\")\n        raise"
        },
        {
            "key_id": 4,
            "fqn": "postgrestq/task_queue.py/TaskQueue/add",
            "imports": [
                "import uuid",
                "import json",
                "from typing import Dict, Any",
                "import psycopg"
            ],
            "code": "def add(self, task: Dict[str, Any], lease_timeout: float, ttl: int = 3) -> str:\n    self.connect()\n    task_id = str(uuid.uuid4())\n    serialized_task = self._serialize(task)\n    \n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"INSERT INTO {self.table_name} \n                (id, queue_name, task, ttl, lease_timeout)\n                VALUES (%s, %s, %s, %s, %s)\"\"\",\n                (task_id, self.queue_name, serialized_task, ttl, lease_timeout)\n            )\n        self.conn.commit()\n        self.logger.info(f\"Added task {task_id} to queue {self.queue_name}\")\n        return task_id\n    except psycopg.Error as e:\n        self.logger.error(f\"Error adding task to queue: {e}\")\n        self.conn.rollback()\n        raise"
        },
        {
            "key_id": 5,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get",
            "imports": [
                "from typing import Tuple, Optional, Dict, Any",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def get(self) -> Tuple[Optional[Dict[str, Any]], Optional[UUID]]:\n    self.connect()\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"UPDATE {self.table_name}\n                SET processing = true,\n                    deadline = current_timestamp + CAST(lease_timeout || ' seconds' AS INTERVAL)\n                WHERE id = (\n                    SELECT id\n                    FROM {self.table_name}\n                    WHERE completed_at IS NULL\n                        AND processing = false\n                        AND queue_name = %s\n                        AND ttl > 0\n                    ORDER BY created_at\n                    FOR UPDATE SKIP LOCKED\n                    LIMIT 1\n                )\n                RETURNING id, task;\"\"\",\n                (self.queue_name,)\n            )\n            result = cur.fetchone()\n        self.conn.commit()\n        \n        if result:\n            task_id, serialized_task = result\n            task = self._deserialize(serialized_task)\n            self.logger.info(f\"Retrieved task {task_id} from queue {self.queue_name}\")\n            return task, UUID(task_id)\n        else:\n            self.logger.info(f\"No tasks available in queue {self.queue_name}\")\n            return None, None\n    except psycopg.Error as e:\n        self.logger.error(f\"Error getting task from queue: {e}\")\n        self.conn.rollback()\n        raise"
        },
        {
            "key_id": 6,
            "fqn": "postgrestq/task_queue.py/TaskQueue/complete",
            "imports": [
                "from typing import Optional",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def complete(self, task_id: Optional[UUID]) -> None:\n    if task_id is None:\n        self.logger.warning(\"Cannot complete task: task_id is None\")\n        return\n    \n    self.connect()\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"UPDATE {self.table_name}\n                SET completed_at = CURRENT_TIMESTAMP\n                WHERE id = %s AND queue_name = %s\"\"\",\n                (str(task_id), self.queue_name)\n            )\n        self.conn.commit()\n        self.logger.info(f\"Marked task {task_id} as completed in queue {self.queue_name}\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error completing task {task_id}: {e}\")\n        self.conn.rollback()\n        raise"
        },
        {
            "key_id": 7,
            "fqn": "postgrestq/task_queue.py/TaskQueue/is_empty",
            "imports": [
                "import psycopg"
            ],
            "code": "def is_empty(self) -> bool:\n    return self.__len__() == 0"
        },
        {
            "key_id": 8,
            "fqn": "postgrestq/task_queue.py/TaskQueue/check_expired_leases",
            "imports": [
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def check_expired_leases(self) -> None:\n    self.connect()\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"SELECT id, task, ttl\n                FROM {self.table_name}\n                WHERE queue_name = %s\n                AND processing = true\n                AND deadline < CURRENT_TIMESTAMP\"\"\",\n                (self.queue_name,)\n            )\n            expired_tasks = cur.fetchall()\n        \n        for task_id, serialized_task, ttl in expired_tasks:\n            task = self._deserialize(serialized_task)\n            new_ttl = ttl - 1\n            \n            if new_ttl > 0:\n                self.logger.info(f\"Rescheduling expired task {task_id} with new TTL {new_ttl}\")\n                with self.conn.cursor() as cur:\n                    cur.execute(\n                        f\"\"\"UPDATE {self.table_name}\n                        SET processing = false,\n                            ttl = %s,\n                            deadline = NULL\n                        WHERE id = %s\"\"\",\n                        (new_ttl, task_id)\n                    )\n            else:\n                self.logger.warning(f\"Task {task_id} has expired and reached TTL 0\")\n                if self.ttl_zero_callback:\n                    self.ttl_zero_callback(UUID(task_id), self._serialize(task))\n                with self.conn.cursor() as cur:\n                    cur.execute(\n                        f\"DELETE FROM {self.table_name} WHERE id = %s\",\n                        (task_id,)\n                    )\n        \n        self.conn.commit()\n    except psycopg.Error as e:\n        self.logger.error(f\"Error checking expired leases: {e}\")\n        self.conn.rollback()\n        raise"
        },
        {
            "key_id": 9,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get_updated_expired_task",
            "imports": [
                "from typing import Tuple, Optional",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"UPDATE {self.table_name}\n                SET ttl = ttl - 1,\n                    processing = false,\n                    deadline = NULL\n                WHERE id = %s AND completed_at IS NULL\n                RETURNING task, ttl\"\"\",\n                (task_id,)\n            )\n            result = cur.fetchone()\n            self.conn.commit()\n            if result:\n                task, ttl = result\n                return self._deserialize(task), ttl\n            return None, None\n    except psycopg.Error as e:\n        self.logger.error(f\"Error updating expired task: {e}\")\n        self.conn.rollback()\n        return None, None"
        },
        {
            "key_id": 12,
            "fqn": "postgrestq/task_queue.py/TaskQueue/reschedule",
            "imports": [
                "from typing import Optional",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def reschedule(self, task_id: Optional[UUID]) -> None:\n    if task_id is None:\n        return\n    \n    try:\n        task, ttl = self.get_updated_expired_task(task_id)\n        if task is None:\n            return\n        \n        if ttl is not None and ttl > 0:\n            self.logger.info(f\"Rescheduling task {task_id} with TTL {ttl}\")\n        elif ttl == 0:\n            self.logger.warning(f\"Task {task_id} has reached maximum retries. Removing from queue.\")\n            self.complete(task_id)\n            if self.ttl_zero_callback:\n                self.ttl_zero_callback(task_id, task)\n        else:\n            self.logger.error(f\"Unexpected TTL value for task {task_id}: {ttl}\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error rescheduling task {task_id}: {e}\")\n        self.conn.rollback()"
        },
        {
            "key_id": 13,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_reset",
            "imports": [
                "import psycopg"
            ],
            "code": "def _reset(self) -> None:\n    try:\n        with self.conn.cursor() as cur:\n            cur.execute(f\"DELETE FROM {self.table_name} WHERE queue_name = %s\", (self.queue_name,))\n        self.conn.commit()\n        self.logger.info(f\"Reset queue {self.queue_name} in table {self.table_name}\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error resetting queue: {e}\")\n        self.conn.rollback()"
        },
        {
            "key_id": 14,
            "fqn": "postgrestq/task_queue.py/TaskQueue/prune_completed_tasks",
            "imports": [
                "import psycopg",
                "from datetime import datetime, timedelta"
            ],
            "code": "def prune_completed_tasks(self, before: int) -> None:\n    try:\n        prune_date = datetime.now() - timedelta(seconds=before)\n        with self.conn.cursor() as cur:\n            cur.execute(\n                f\"\"\"DELETE FROM {self.table_name}\n                WHERE queue_name = %s\n                AND completed_at IS NOT NULL\n                AND completed_at < %s\"\"\",\n                (self.queue_name, prune_date)\n            )\n            deleted_count = cur.rowcount\n        self.conn.commit()\n        self.logger.info(f\"Pruned {deleted_count} completed tasks from queue {self.queue_name}\")\n    except psycopg.Error as e:\n        self.logger.error(f\"Error pruning completed tasks: {e}\")\n        self.conn.rollback()"
        },
        {
            "key_id": 15,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__iter__",
            "imports": [
                "from typing import Iterator, Tuple, Optional, Dict, Any",
                "from uuid import UUID"
            ],
            "code": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:\n    while True:\n        task, task_id = self.get()\n        if task is None:\n            break\n        try:\n            yield task, task_id\n        finally:\n            if task_id is not None:\n                self.complete(task_id)"
        }
    ]
}