{
    "implementation": [
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/__init__",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def __init__(self, dsn: str, queue_name: str, table_name: str = \"task_queue\", reset: bool = False, create_table: bool = False, ttl_zero_callback: Optional[\n            Callable[[UUID, Optional[str]], None]\n        ] = None):",
            "comment": "Initialize the task queue.\n\nNote: a task has to be at any given time either in the task\nqueue or in the processing queue. If a task is moved from one\nqueue to the other it has to be in an atomic fashion!\n\nParameters\n----------\ndsn : str\n    connection string for the Postgres server\nqueue_name : str\n    name of the task queue\ntable_name: str\n    name of the table where the queue is stored\nreset : bool\n    If true, reset existing tasks in the DB that have `queue_name` as\n    the queue_name.\ncreate_table : bool\n    If set to true it creates the table in the DB, it's nice to have\n    if you are running the tests with a dummy DB\nttl_zero_callback : callable\n    a function that is called if a task's ttl <= 0. The callback\n    needs to accept two parameters, the task_id and the task.",
            "comment_free_code": "def __init__(self, dsn: str, queue_name: str, table_name: str='task_queue', reset: bool=False, create_table: bool=False, ttl_zero_callback: Optional[Callable[[UUID, Optional[str]], None]]=None):\n    \n    self._queue_name = queue_name\n    self._dsn = dsn\n    self._table_name = table_name\n    self.ttl_zero_callback = ttl_zero_callback\n    self.connect()\n    if create_table:\n        self._create_queue_table()\n    if reset:\n        self._reset()",
            "start_lineno": 13,
            "end_lineno": 61,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                0,
                1,
                13
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/connect",
                    "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
                    "postgrestq/task_queue.py/TaskQueue/_reset"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 0,
            "gen_code": "def __init__(self, dsn: str, queue_name: str, table_name: str = 'task_queue', reset: bool = False, create_table: bool = False, ttl_zero_callback: Optional[Callable[[UUID, Optional[str]], None]] = None):\n    self.dsn = dsn\n    self.queue_name = queue_name\n    self.table_name = table_name\n    self.reset = reset\n    self.create_table = create_table\n    self.ttl_zero_callback = ttl_zero_callback\n    self.logger = logging.getLogger(__name__)\n    if self.create_table:\n        self._create_queue_table()\n    if self.reset:\n        self._reset()",
            "gen_import": [
                "import logging",
                "from typing import Callable, Optional",
                "from uuid import UUID",
                "import psycopg"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/connect",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def connect(self) -> None:",
            "comment": "Establish a connection to Postgres.\nIf a connection already exists, it's overwritten.",
            "comment_free_code": "def connect(self) -> None:\n    \n    self.conn = connect(self._dsn)",
            "start_lineno": 63,
            "end_lineno": 68,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 1,
            "gen_code": "def connect(self) -> None:\n    try:\n        self.conn = psycopg.connect(self.dsn)\n        self.cur = self.conn.cursor()\n        self.logger.info('Successfully connected to the database')\n    except Exception as e:\n        self.logger.error(f'Error connecting to the database: {e}')\n        raise",
            "gen_import": [
                "import psycopg",
                "import logging"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def _create_queue_table(self) -> None:",
            "comment": "Creates a task_queue table",
            "comment_free_code": "def _create_queue_table(self) -> None:\n    \n    with self.conn.cursor() as cur:\n        cur.execute(sql.SQL('CREATE TABLE IF NOT EXISTS {} (\\n                            id UUID PRIMARY KEY,\\n                            queue_name TEXT NOT NULL,\\n                            task JSONB NOT NULL,\\n                            ttl INT NOT NULL,\\n                            created_at TIMESTAMP NOT NULL\\n                                DEFAULT CURRENT_TIMESTAMP,\\n                            processing BOOLEAN NOT NULL\\n                                DEFAULT false,\\n                            lease_timeout FLOAT,\\n                            deadline TIMESTAMP,\\n                            completed_at TIMESTAMP\\n                        )').format(sql.Identifier(self._table_name)))",
            "start_lineno": 70,
            "end_lineno": 93,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 2,
            "gen_code": "def _create_queue_table(self) -> None:\n    create_table_query = '''\n    CREATE TABLE IF NOT EXISTS task_queue (\n        id UUID PRIMARY KEY,\n        queue_name TEXT NOT NULL,\n        task JSONB NOT NULL,\n        ttl INT NOT NULL,\n        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n        processing BOOLEAN NOT NULL DEFAULT false,\n        lease_timeout FLOAT,\n        deadline TIMESTAMP,\n        completed_at TIMESTAMP\n    )'''\n    try:\n        self.cur.execute(create_table_query)\n        self.conn.commit()\n        self.logger.info('Table task_queue created successfully')\n    except Exception as e:\n        self.logger.error(f'Error creating task_queue table: {e}')\n        raise",
            "gen_import": [
                "import logging"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/__len__",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def __len__(self) -> int:",
            "comment": "Returns the length of processing or to be processed tasks",
            "comment_free_code": "def __len__(self) -> int:\n    \n    with self.conn.cursor() as cursor:\n        cursor.execute(sql.SQL('\\n                SELECT count(1) as count\\n                FROM {}\\n                WHERE queue_name = %s\\n                    AND completed_at IS NULL\\n            ').format(sql.Identifier(self._table_name)), (self._queue_name,))\n        row = cursor.fetchone()\n        count: int = row[0] if row else 0\n        self.conn.commit()\n        return count",
            "start_lineno": 95,
            "end_lineno": 114,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 3,
            "gen_code": "def __len__(self) -> int:\n    with psycopg.connect(self.dsn, row_factory=dict_row) as conn:\n        with conn.cursor() as cur:\n            cur.execute(f'SELECT COUNT(*) FROM {self.table_name} WHERE queue_name = %s AND completed_at IS NULL', (self.queue_name,))\n            result = cur.fetchone()\n            return result['count'] if result else 0",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/add",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def add(self, task: Dict[str, Any], lease_timeout: float, ttl: int = 3) -> str:",
            "comment": "Add a task to the task queue.\n\nParameters\n----------\ntask : something that can be JSON-serialized\nlease_timeout : float\n    lease timeout in seconds, i.e. how much time we give the\n    task to process until we can assume it didn't succeed\nttl : int\n    Number of (re-)tries, including the initial one, in case the\n    job dies.\n\nReturns\n-------\ntask_id :\n    The random UUID that was generated for this task",
            "comment_free_code": "def add(self, task: Dict[str, Any], lease_timeout: float, ttl: int=3) -> str:\n    \n    lease_timeout = float(lease_timeout)\n    id_ = str(uuid4())\n    serialized_task = self._serialize(task)\n    with self.conn.cursor() as cursor:\n        cursor.execute(sql.SQL('\\n                INSERT INTO {} (\\n                    id,\\n                    queue_name,\\n                    task,\\n                    ttl,\\n                    lease_timeout\\n                )\\n                VALUES (%s, %s, %s, %s, %s)\\n            ').format(sql.Identifier(self._table_name)), (id_, self._queue_name, serialized_task, ttl, lease_timeout))\n        self.conn.commit()\n    return id_",
            "start_lineno": 116,
            "end_lineno": 162,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                6
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/_serialize"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 4,
            "gen_code": "def add(self, task: dict, lease_timeout: float, ttl: int = 3) -> str:\n    task_id = str(uuid4())\n    serialized_task = json.dumps(task)\n    with psycopg.connect(self.dsn) as conn:\n        with conn.cursor() as cur:\n            cur.execute(f'INSERT INTO {self.table_name} (id, queue_name, task, ttl, lease_timeout, created_at, processing) VALUES (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP, FALSE)', (task_id, self.queue_name, serialized_task, ttl, lease_timeout))\n            conn.commit()\n    return task_id",
            "gen_import": [
                "import psycopg",
                "from uuid import uuid4",
                "import json"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/get",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def get(self) -> Tuple[Optional[Dict[str, Any]], Optional[UUID]]:",
            "comment": "Get a task from the task queue (non-blocking).\n\nThis statement marks the next available task in the queue as\n\"processing\" and returns its ID and task details. The query\nuses a FOR UPDATE SKIP LOCKED clause to lock the selected\ntask so that other workers can't select the same task simultaneously.\n\nAfter executing the query, the method fetches the result using\ncur.fetchone(). If no task is found, the method returns None, None.\nOtherwise, it returns the task and its ID.\n\nNote that this method is non-blocking, which means it returns\nimmediately even if there is no task available in the queue..\nIn order to mark that task as done, you have\nto use:\n\n    >>> task, task_id = taskqueue.get()\n    >>> # do something\n    >>> taskqueue.complete(task_id)\n\nAfter some time (i.e. `lease_timeout`) tasks expire and are\nmarked as not processing and the TTL is decreased by\none. If TTL is still > 0 the task will be retried.\n\nNote, this method is non-blocking, i.e. it returns immediately\neven if there is nothing to return. See below for the return\nvalue for this case.\n\nReturns\n-------\n(task, task_id) :\n    The next item from the task list or (None, None) if it's\n    empty",
            "comment_free_code": "def get(self) -> Tuple[Optional[Dict[str, Any]], Optional[UUID]]:\n    \n    conn = self.conn\n    with conn.cursor() as cur:\n        cur.execute(sql.SQL(\"\\n                UPDATE {}\\n                SET processing = true,\\n                    deadline =\\n                        current_timestamp +\\n                        CAST(lease_timeout || ' seconds' AS INTERVAL)\\n                WHERE id = (\\n                    SELECT id\\n                    FROM {}\\n                    WHERE completed_at IS NULL\\n                        AND processing = false\\n                        AND queue_name = %s\\n                        AND ttl > 0\\n                    ORDER BY created_at\\n                    FOR UPDATE SKIP LOCKED\\n                    LIMIT 1\\n                )\\n                RETURNING id, task;\").format(sql.Identifier(self._table_name), sql.Identifier(self._table_name)), (self._queue_name,))\n        row = cur.fetchone()\n        if row is None:\n            return (None, None)\n        (task_id, task) = row\n        logger.info(f'Got task with id {task_id}')\n        conn.commit()\n        return (task, task_id)",
            "start_lineno": 164,
            "end_lineno": 236,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 5,
            "gen_code": "def get(self) -> Tuple[Optional[dict], Optional[str]]:\n    with psycopg.connect(self.dsn, row_factory=dict_row) as conn:\n        with conn.cursor() as cur:\n            cur.execute(f\"\"\"UPDATE {self.table_name} SET processing = TRUE, deadline = CURRENT_TIMESTAMP + (lease_timeout || ' seconds')::INTERVAL WHERE id = (SELECT id FROM {self.table_name} WHERE completed_at IS NULL AND processing = FALSE AND queue_name = %s AND ttl > 0 ORDER BY created_at FOR UPDATE SKIP LOCKED LIMIT 1) RETURNING id, task\"\"\", (self.queue_name,))\n            result = cur.fetchone()\n            conn.commit()\n            if result:\n                return (json.loads(result['task']), result['id'])\n            return (None, None)",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row",
                "from typing import Tuple, Optional",
                "import json"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/complete",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def complete(self, task_id: Optional[UUID]) -> None:",
            "comment": "Mark a task as completed.\n\nMarks a task as completed by setting completed_at column by\nthe current timestamp.\n\nIf the job is in the queue, which happens if it took too long\nand it expired, is removed from that too.\n\n\nParameters\n----------\ntask_id : UUID | None\n    the task ID",
            "comment_free_code": "def complete(self, task_id: Optional[UUID]) -> None:\n    \n    logger.info(f'Marking task {task_id} as completed')\n    conn = self.conn\n    with conn.cursor() as cur:\n        cur.execute(sql.SQL('\\n                UPDATE {}\\n                SET completed_at = current_timestamp,\\n                    processing = false\\n                WHERE id = %s').format(sql.Identifier(self._table_name)), (task_id,))\n        conn.commit()",
            "start_lineno": 238,
            "end_lineno": 267,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 6,
            "gen_code": "def complete(self, task_id: Optional[str]) -> None:\n    if task_id is None:\n        self.logger.warning('Attempted to complete a task with None ID')\n        return\n    with psycopg.connect(self.dsn) as conn:\n        with conn.cursor() as cur:\n            cur.execute(f'UPDATE {self.table_name} SET completed_at = CURRENT_TIMESTAMP WHERE id = %s', (task_id,))\n            conn.commit()",
            "gen_import": [
                "import psycopg"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/is_empty",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def is_empty(self) -> bool:",
            "comment": "Check if the task queue is empty.\n\nInternally, this function also checks the currently processed\ntasks for expiration and teals with TTL and re-scheduling them\ninto the task queue by marking them as not processing.\n\nReturns\n-------\nbool",
            "comment_free_code": "def is_empty(self) -> bool:\n    \n    self.check_expired_leases()\n    return len(self) == 0",
            "start_lineno": 269,
            "end_lineno": 282,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                9
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/check_expired_leases"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 7,
            "gen_code": "def is_empty(self) -> bool:\n    self.connect()\n    with self.conn.cursor(row_factory=dict_row) as cur:\n        cur.execute(\n            f\"SELECT COUNT(*) AS count FROM {self.table_name} WHERE queue_name = %s AND completed_at IS NULL\",\n            (self.queue_name,)\n        )\n        result = cur.fetchone()\n        if result['count'] == 0:\n            return True\n        else:\n            self.check_expired_leases()\n            cur.execute(\n                f\"SELECT COUNT(*) AS count FROM {self.table_name} WHERE queue_name = %s AND completed_at IS NULL\",\n                (self.queue_name,)\n            )\n            result = cur.fetchone()\n            return result['count'] == 0",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/check_expired_leases",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def check_expired_leases(self) -> None:",
            "comment": "Check for expired leases and put the task back if needed.\n\nThis method goes through all tasks that are currently processed\nand checks if their deadline expired. If not we assume the\nworker died. We decrease the TTL and if TTL is still > 0 we\nreschedule the task into the task queue or, if the TTL is\nexhausted, we mark the task as completed by setting\n`completed_at` column with current timestamp and call the\nexpired task callback if it's set.\n\nNote: lease check is only performed against the tasks\nthat are processing.",
            "comment_free_code": "def check_expired_leases(self) -> None:\n    \n    with self.conn.cursor() as cur:\n        cur.execute(sql.SQL('\\n                SELECT id\\n                FROM {}\\n                WHERE completed_at IS NULL\\n                    AND processing = true\\n                    AND queue_name = %s\\n                    AND deadline < NOW()\\n                ORDER BY created_at;\\n            ').format(sql.Identifier(self._table_name)), (self._queue_name,))\n        expired_tasks = cur.fetchall()\n        self.conn.commit()\n        logger.debug(f'Expired tasks {expired_tasks}')\n    for row in expired_tasks:\n        task_id: UUID = row[0]\n        logger.debug(f'Got expired task with id {task_id}')\n        (task, ttl) = self.get_updated_expired_task(task_id)\n        if ttl is None:\n            logger.info(f'Task {task_id} was marked completed while we checked for expired leases, nothing to do.')\n            continue\n        if ttl <= 0:\n            logger.error(f'Job {task} with id {task_id} failed too many times, marking it as completed.')\n            self.conn.commit()\n            self.complete(task_id)\n            if self.ttl_zero_callback:\n                self.ttl_zero_callback(task_id, task)\n        self.conn.commit()",
            "start_lineno": 284,
            "end_lineno": 347,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                8,
                4
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/get_updated_expired_task",
                    "postgrestq/task_queue.py/TaskQueue/complete"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 8,
            "gen_code": "def check_expired_leases(self) -> None:\n    self.connect()\n    with self.conn.cursor(row_factory=dict_row) as cur:\n        cur.execute(\n            f\"SELECT id, lease_timeout FROM {self.table_name} WHERE queue_name = %s AND processing = TRUE AND deadline <= %s\",\n            (self.queue_name, datetime.utcnow())\n        )\n        for row in cur.fetchall():\n            task_id, lease_timeout = row['id'], row['lease_timeout']\n            updated_task, ttl = self.get_updated_expired_task(task_id)\n            if ttl > 0:\n                self.reschedule(task_id)\n            else:\n                cur.execute(\n                    f\"UPDATE {self.table_name} SET completed_at = %s WHERE id = %s\",\n                    (datetime.utcnow(), task_id)\n                )\n                if self.ttl_zero_callback is not None:\n                    self.ttl_zero_callback(task_id, updated_task)",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row",
                "from datetime import datetime, timedelta"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/get_updated_expired_task",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:",
            "comment": "Given the id of an expired task, it tries to reschedule the\ntask by marking it as not processing, resetting the deadline\nand decreaasing TTL by one. It returns None if the task is\nalready updated or (being updated) by another worker.\n\nReturns\n-------\n(task, ttl) :\n    The updated task and ttl values for the expired task with\n    task_id after it's rescheduled",
            "comment_free_code": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:\n    \n    with self.conn.cursor() as cur:\n        cur.execute(sql.SQL('\\n                UPDATE {}\\n                SET ttl = ttl - 1,\\n                    processing = false,\\n                    deadline = NULL\\n                WHERE id = (\\n                    SELECT id\\n                    FROM {}\\n                    WHERE completed_at IS NULL\\n                        AND processing = true\\n                        AND queue_name = %s\\n                        AND id = %s\\n                    FOR UPDATE SKIP LOCKED\\n                    LIMIT 1\\n                )\\n                RETURNING task, ttl;\\n            ').format(sql.Identifier(self._table_name), sql.Identifier(self._table_name)), (self._queue_name, task_id))\n        updated_row = cur.fetchone()\n        if updated_row is None:\n            return (None, None)\n        (task, ttl) = updated_row\n        task = self._serialize(task)\n        return (task, ttl)",
            "start_lineno": 349,
            "end_lineno": 401,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                6
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/_serialize"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 9,
            "gen_code": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:\n    self.connect()\n    with self.conn.cursor(row_factory=dict_row) as cur:\n        cur.execute(\n            f\"SELECT task, ttl FROM {self.table_name} WHERE id = %s\",\n            (task_id,)\n        )\n        result = cur.fetchone()\n        if result is None:\n            return None, None\n        task, ttl = self._deserialize(result['task']), result['ttl'] - 1\n        cur.execute(\n            f\"UPDATE {self.table_name} SET processing = FALSE, ttl = %s, deadline = NULL WHERE id = %s\",\n            (ttl, task_id)\n        )\n        return task, ttl",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/_serialize",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def _serialize(self, task: Any) -> str:",
            "comment": null,
            "comment_free_code": "def _serialize(self, task: Any) -> str:\n    return json.dumps(task, sort_keys=True)",
            "start_lineno": 403,
            "end_lineno": 404,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 10,
            "gen_code": "def _serialize(self, task: Any) -> str:\n    try:\n        return json.dumps(task)\n    except TypeError as e:\n        self.logger.error(f'Error serializing task: {e}')\n        raise",
            "gen_import": [
                "import json",
                "import logging"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/_deserialize",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def _deserialize(self, blob: str) -> Any:",
            "comment": null,
            "comment_free_code": "def _deserialize(self, blob: str) -> Any:\n    return json.loads(blob)",
            "start_lineno": 406,
            "end_lineno": 407,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 11,
            "gen_code": "def _deserialize(self, blob: str) -> Any:\n    try:\n        return json.loads(blob)\n    except json.JSONDecodeError as e:\n        self.logger.error(f'Failed to deserialize task data: {blob}', exc_info=e)\n        raise ValueError('Invalid task data format') from e",
            "gen_import": [
                "import json",
                "from typing import Any"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/reschedule",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def reschedule(self, task_id: Optional[UUID]) -> None:",
            "comment": "Move a task back from the processing- to the task queue.\n\nWorkers can use this method to \"drop\" a work unit in case of\neviction.\n\nThis function does not modify the TTL.\n\nParameters\n----------\ntask_id : str\n    the task ID\n\nRaises\n------\nValueError :\n    Task is not being processed, and cannot be re-scheduled",
            "comment_free_code": "def reschedule(self, task_id: Optional[UUID]) -> None:\n    \n    if not isinstance(task_id, UUID):\n        raise ValueError('task_id must be a UUID')\n    logger.info(f'Rescheduling task {task_id}..')\n    conn = self.conn\n    with conn.cursor() as cur:\n        cur.execute(sql.SQL('\\n                UPDATE {}\\n                SET processing = false,\\n                    deadline = NULL\\n                WHERE id = (\\n                    SELECT id\\n                    FROM {}\\n                    WHERE processing = true\\n                        AND id = %s\\n                    FOR UPDATE SKIP LOCKED\\n                )\\n                RETURNING id;').format(sql.Identifier(self._table_name), sql.Identifier(self._table_name)), (task_id,))\n        found = cur.fetchone()\n        conn.commit()\n        if found is None:\n            raise ValueError(f'Task {task_id} does not exist.')",
            "start_lineno": 409,
            "end_lineno": 458,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 12,
            "gen_code": "def reschedule(self, task_id: Optional[UUID]) -> None:\n    if task_id is None:\n        raise ValueError('Task ID cannot be None')\n    self.connect()\n    with self.conn.cursor() as cur:\n        cur.execute(\n            f\"UPDATE {self.table_name} SET processing = FALSE, deadline = NULL WHERE id = %s\",\n            (task_id,)\n        )\n        if cur.rowcount == 0:\n            raise ValueError('Task is not being processed, and cannot be re-scheduled')",
            "gen_import": [
                "import psycopg"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/_reset",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def _reset(self) -> None:",
            "comment": "Delete all tasks in the DB with our queue name.",
            "comment_free_code": "def _reset(self) -> None:\n    \n    with self.conn.cursor() as cursor:\n        cursor.execute(sql.SQL('DELETE FROM {} WHERE queue_name = %s ').format(sql.Identifier(self._table_name)), (self._queue_name,))\n        self.conn.commit()",
            "start_lineno": 460,
            "end_lineno": 470,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 13,
            "gen_code": "def _reset(self) -> None:\n    reset_query = f'DELETE FROM {self.table_name} WHERE queue_name = %s;'\n    try:\n        self.cur.execute(reset_query, (self.queue_name,))\n        self.conn.commit()\n        self.logger.info(f'All tasks in queue {self.queue_name} have been deleted')\n    except Exception as e:\n        self.logger.error(f'Error resetting the task queue: {e}')\n        raise",
            "gen_import": [
                "import logging"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/prune_completed_tasks",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def prune_completed_tasks(self, before: int) -> None:",
            "comment": "Delete all completed tasks older than the given number of seconds.\n\nParameters\n----------\nbefore : int\n    Seconds in the past from which completed task will be deleted",
            "comment_free_code": "def prune_completed_tasks(self, before: int) -> None:\n    \n    before = int(before)\n    logger.info(f'Pruning all tasks completed more than {before} second(s) ago.')\n    with self.conn.cursor() as cursor:\n        cursor.execute(sql.SQL(\"\\n                    DELETE FROM {}\\n                    WHERE queue_name = %s\\n                        AND completed_at IS NOT NULL\\n                        AND processing = false\\n                        AND completed_at < current_timestamp - CAST(\\n                            %s || ' seconds' AS INTERVAL);\\n                    \").format(sql.Identifier(self._table_name)), (self._queue_name, before))\n        self.conn.commit()",
            "start_lineno": 472,
            "end_lineno": 501,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 14,
            "gen_code": "def prune_completed_tasks(self, before: int) -> None:\n    prune_query = f'''DELETE FROM {self.table_name} WHERE completed_at IS NOT NULL AND completed_at < (CURRENT_TIMESTAMP - INTERVAL '%s seconds') AND queue_name = %s;'''\n    try:\n        self.cur.execute(prune_query, (before, self.queue_name,))\n        self.conn.commit()\n        self.logger.info(f'Completed tasks older than {before} seconds have been pruned from the queue {self.queue_name}')\n    except Exception as e:\n        self.logger.error(f'Error pruning completed tasks: {e}')\n        raise",
            "gen_import": [
                "import logging"
            ]
        },
        {
            "path": "/home/gudako/repo/repogen/data/postgres-tq/postgrestq/task_queue.py",
            "relative_path": "postgrestq/task_queue.py",
            "fqn_list": "postgrestq/task_queue.py/TaskQueue/__iter__",
            "class": "postgrestq/task_queue.py.TaskQueue",
            "signature": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:",
            "comment": "Iterate over tasks and mark them as complete.\n\nThis allows to easily iterate over the tasks to process them:\n\n    >>> for task in task_queue:\n            execute_task(task)\n\nit takes care of marking the tasks as done once they are processed\nand checking the emptiness of the queue before leaving.\n\nNotice that this iterator can wait for a long time waiting for work\nunits to appear, depending on the value set as lease_timeout.\n\nYields\n-------\n(any, str) :\n    A tuple containing the task content and its id",
            "comment_free_code": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:\n    \n    while True:\n        (task, id_) = self.get()\n        if id_ is not None:\n            yield (task, id_)\n            self.complete(id_)\n        if self.is_empty():\n            logger.debug(f'{self._queue_name} is empty. Nothing to process anymore...')\n            break",
            "start_lineno": 503,
            "end_lineno": 535,
            "local_variables": {
                "module": [
                    "logger = logging.getLogger(__name__)"
                ]
            },
            "Type": "FunctionDef",
            "Dependencies": [
                10,
                3,
                4
            ],
            "local_import": [],
            "third_import": [
                [
                    "postgrestq/task_queue.py",
                    "import json",
                    "json"
                ],
                [
                    "postgrestq/task_queue.py",
                    "import logging",
                    "logging"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import uuid4",
                    "uuid.uuid4"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from uuid import UUID",
                    "uuid.UUID"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Optional",
                    "typing.Optional"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Tuple",
                    "typing.Tuple"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Iterator",
                    "typing.Iterator"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Dict",
                    "typing.Dict"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Any",
                    "typing.Any"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from typing import Callable",
                    "typing.Callable"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import sql",
                    "psycopg.sql"
                ],
                [
                    "postgrestq/task_queue.py",
                    "from psycopg import connect",
                    "psycopg.connect"
                ]
            ],
            "categorized_dependencies": {
                "Intra-class Dependency": [
                    "postgrestq/task_queue.py/TaskQueue/is_empty",
                    "postgrestq/task_queue.py/TaskQueue/get",
                    "postgrestq/task_queue.py/TaskQueue/complete"
                ],
                "Intra-file Dependency": [],
                "Cross-file Dependency": [],
                "Class Dependency": []
            },
            "cov": true,
            "syn": false,
            "keyid": 15,
            "gen_code": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:\n    self.connect()\n    while not self.is_empty():\n        task, task_id = self.get()\n        if task is not None:\n            yield task, task_id\n            self.complete(task_id)\n        else:\n            break",
            "gen_import": [
                "import psycopg",
                "from psycopg.rows import dict_row",
                "from uuid import UUID"
            ]
        }
    ]
}