{
    "implementation": [
        {
            "key_id": 0,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/__init__",
            "imports": [
                "import numpy as np"
            ],
            "code": "class ConstrainedLinearRegression:\n    def __init__(self, fit_intercept: bool = True, alpha: float = 0.0):\n        self.fit_intercept = fit_intercept\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n        \n        # Validation for alpha\n        if not isinstance(alpha, float) or alpha < 0:\n            raise ValueError('alpha must be a non-negative float.')\n        \n        # Initialize placeholders for model parameters\n        self.coef_ = np.array([])\n        if self.fit_intercept:\n            self.intercept_ = 0.0"
        },
        {
            "key_id": 4,
            "fqn": "constrainedlr/validation.py/validate_constraint_features_all_strings_or_all_int",
            "imports": [
                "from typing import Dict"
            ],
            "code": "def validate_constraint_features_all_strings_or_all_int(constraints: Dict) -> None:\n    if not constraints:\n        return\n    if all(isinstance(key, str) for key in constraints.keys()):\n        return\n    if all(isinstance(key, int) for key in constraints.keys()):\n        return\n    raise ValueError('Constraint keys must be all strings or all integers.')"
        },
        {
            "key_id": 5,
            "fqn": "constrainedlr/validation.py/get_clean_feature_names_from_pipeline",
            "imports": [
                "from typing import List"
            ],
            "code": "def get_clean_feature_names_from_pipeline(feature_names: List[str]) -> List[str]:\n    return [name.split('__')[-1] for name in feature_names]"
        },
        {
            "key_id": 6,
            "fqn": "constrainedlr/validation.py/validate_feature_names_in_constraints",
            "imports": [
                "from typing import List, Dict"
            ],
            "code": "def validate_feature_names_in_constraints(constraints: Dict, feature_names: List[str]) -> None:\n    clean_feature_names = get_clean_feature_names_from_pipeline(feature_names)\n    for constraint in constraints.keys():\n        if constraint not in clean_feature_names:\n            raise ValueError(f'Constraint feature {constraint} is not a valid feature name.')"
        },
        {
            "key_id": 7,
            "fqn": "constrainedlr/validation.py/convert_feature_names_to_indices",
            "imports": [
                "from typing import Dict, List"
            ],
            "code": "def convert_feature_names_to_indices(constraints: Dict, feature_names_in_: List[str]) -> Dict:\n    clean_feature_names = get_clean_feature_names_from_pipeline(feature_names_in_)\n    return {clean_feature_names.index(key): value for key, value in constraints.items() if key in clean_feature_names}"
        },
        {
            "key_id": 8,
            "fqn": "constrainedlr/validation.py/validate_coefficients_sign_constraints",
            "imports": [
                "from typing import Dict, Optional, Union",
                "import numpy as np",
                "import pandas as pd"
            ],
            "code": "def validate_coefficients_sign_constraints(coefficients_sign_constraints: Optional[Dict], X: Union[np.ndarray, pd.DataFrame], feature_names_in_: Optional[List[str]]) -> Dict:\n    if coefficients_sign_constraints is None:\n        return {}\n    if isinstance(X, pd.DataFrame):\n        feature_names = X.columns.tolist()\n    elif feature_names_in_ is not None:\n        feature_names = feature_names_in_\n    else:\n        raise ValueError('Feature names must be provided for non-DataFrame inputs.')\n    validate_constraint_features_all_strings_or_all_int(coefficients_sign_constraints)\n    return {feature_names.index(key) if isinstance(key, str) else key: value for key, value in coefficients_sign_constraints.items()}"
        },
        {
            "key_id": 9,
            "fqn": "constrainedlr/validation.py/validate_intercept_sign_constraint",
            "imports": [
                "from typing import Union"
            ],
            "code": "def validate_intercept_sign_constraint(intercept_sign_constraint: Union[int, str]) -> int:\n    if intercept_sign_constraint in ('positive', 1):\n        return 1\n    elif intercept_sign_constraint in ('negative', -1):\n        return -1\n    elif intercept_sign_constraint == 0:\n        return 0\n    else:\n        raise ValueError('Invalid value for intercept_sign_constraint. Allowed values are \"positive\", \"negative\", or 0.')"
        },
        {
            "key_id": 10,
            "fqn": "constrainedlr/validation.py/validate_coefficients_range_constraints",
            "imports": [
                "from typing import Optional, Union, dict",
                "import numpy as np",
                "import pandas as pd"
            ],
            "code": "def validate_coefficients_range_constraints(coefficients_range_constraints: Optional[dict], X: Union[np.ndarray, pd.DataFrame], feature_names_in_: Optional[np.ndarray[str]]) -> dict:\n    if not coefficients_range_constraints:\n        return {}\n    validated_constraints = {}\n    for feature, constraints in coefficients_range_constraints.items():\n        if 'lower' in constraints and 'upper' in constraints:\n            if constraints['lower'] > constraints['upper']:\n                raise ValueError(f'Lower bound cannot be greater than upper bound for feature {feature}')\n        validated_constraints[feature] = constraints\n    return validated_constraints"
        },
        {
            "key_id": 1,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/fit",
            "imports": [
                "from typing import Union, Optional",
                "import numpy as np",
                "import pandas as pd",
                "from .validation import validate_intercept_sign_constraint, validate_coefficients_range_constraints, validate_coefficients_sign_constraints, validate_constraint_features_all_strings_or_all_int, convert_feature_names_to_indices, get_clean_feature_names_from_pipeline, validate_feature_names_in_constraints"
            ],
            "code": "def fit(self, X: Union[np.ndarray, pd.DataFrame], y: np.ndarray, sample_weight: Optional[np.ndarray] = None, coefficients_sign_constraints: Optional[dict] = None, coefficients_range_constraints: Optional[dict] = None, intercept_sign_constraint: Union[int, str] = 0, coefficients_sum_constraint: Optional[float] = None) -> 'ConstrainedLinearRegression':\n    # Validate input constraints\n    intercept_sign = validate_intercept_sign_constraint(intercept_sign_constraint)\n    coefficients_range = validate_coefficients_range_constraints(coefficients_range_constraints, X, None if isinstance(X, np.ndarray) else X.columns)\n    # Additional validation logic here\n    # Placeholder for fitting logic\n    # This should include the optimization process considering the constraints\n    # Update model parameters\n    self.coef_ = np.zeros(X.shape[1])  # Placeholder for actual coefficients\n    self.intercept_ = 0 if self.fit_intercept else None  # Placeholder for actual intercept\n    return self"
        },
        {
            "key_id": 2,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/predict",
            "imports": [
                "import numpy as np"
            ],
            "code": "def predict(self, X: Union[np.ndarray, pd.DataFrame]) -> np.ndarray:\n    if self.coef_ is None or (self.fit_intercept and self.intercept_ is None):\n        raise Exception('Model must be fitted before prediction.')\n    return np.dot(X, self.coef_) + (self.intercept_ if self.fit_intercept else 0)"
        },
        {
            "key_id": 3,
            "fqn": "constrainedlr/model.py/ConstrainedLinearRegression/get_feature_names_out",
            "imports": [
                "import numpy as np"
            ],
            "code": "def get_feature_names_out(self) -> np.ndarray[str]:\n    if self.coef_ is None:\n        raise Exception('Model must be fitted before getting feature names.')\n    return np.array(['x' + str(i) for i in range(len(self.coef_))])"
        }
    ]
}