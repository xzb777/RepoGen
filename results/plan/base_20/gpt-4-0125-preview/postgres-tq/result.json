{
    "implementation": [
        {
            "key_id": 0,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__init__",
            "imports": [
                "import logging",
                "from typing import Optional, Callable",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "class TaskQueue:\n    def __init__(self, dsn: str, queue_name: str, table_name: str = 'task_queue', reset: bool = False, create_table: bool = False, ttl_zero_callback: Optional[\n            Callable[[UUID, Optional[str]], None]\n        ] = None):\n        self.dsn = dsn\n        self.queue_name = queue_name\n        self.table_name = table_name\n        self.reset = reset\n        self.create_table = create_table\n        self.ttl_zero_callback = ttl_zero_callback\n        self.logger = logging.getLogger(__name__)\n        self.connect()\n        if self.create_table:\n            self._create_queue_table()\n        if self.reset:\n            self._reset()\n\n    def connect(self) -> None:\n        try:\n            self.conn = psycopg.connect(self.dsn)\n            self.cur = self.conn.cursor()\n        except Exception as e:\n            self.logger.error(f'Failed to connect to the database: {e}')\n            raise\n\n    def _create_queue_table(self) -> None:\n        create_table_query = f\"\"\"CREATE TABLE IF NOT EXISTS {self.table_name} (\n            id UUID PRIMARY KEY,\n            queue_name TEXT NOT NULL,\n            task JSONB NOT NULL,\n            ttl INT NOT NULL,\n            created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n            processing BOOLEAN NOT NULL DEFAULT false,\n            lease_timeout FLOAT,\n            deadline TIMESTAMP,\n            completed_at TIMESTAMP\n        )\"\"\"\n        try:\n            self.cur.execute(create_table_query)\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to create table {self.table_name}: {e}')\n            self.conn.rollback()\n\n    def _serialize(self, task: Any) -> str:\n        return json.dumps(task)\n\n    def _deserialize(self, blob: str) -> Any:\n        return json.loads(blob)"
        },
        {
            "key_id": 2,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_create_queue_table",
            "imports": [
                "import json",
                "import logging",
                "from typing import Optional, Callable",
                "from uuid import UUID",
                "import psycopg"
            ],
            "code": "def _create_queue_table(self) -> None:\n        create_table_query = f\"\"\"CREATE TABLE IF NOT EXISTS {self.table_name} (\n            id UUID PRIMARY KEY,\n            queue_name TEXT NOT NULL,\n            task JSONB NOT NULL,\n            ttl INT NOT NULL,\n            created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n            processing BOOLEAN NOT NULL DEFAULT false,\n            lease_timeout FLOAT,\n            deadline TIMESTAMP,\n            completed_at TIMESTAMP\n        )\"\"\"\n        try:\n            self.cur.execute(create_table_query)\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to create table {self.table_name}: {e}')\n            self.conn.rollback()"
        },
        {
            "key_id": 13,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_reset",
            "imports": [],
            "code": "def _reset(self) -> None:\n        reset_query = f'DELETE FROM {self.table_name} WHERE queue_name = %s;'\n        try:\n            self.cur.execute(reset_query, (self.queue_name,))\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to reset table {self.table_name} for queue {self.queue_name}: {e}')\n            self.conn.rollback()"
        },
        {
            "key_id": 14,
            "fqn": "postgrestq/task_queue.py/TaskQueue/prune_completed_tasks",
            "imports": [
                "import time"
            ],
            "code": "def prune_completed_tasks(self, before: int) -> None:\n        current_time = int(time.time())\n        prune_query = f\"\"\"DELETE FROM {self.table_name} WHERE completed_at IS NOT NULL AND\n                      EXTRACT(EPOCH FROM (NOW() - completed_at)) > %s;\"\"\"\n        try:\n            self.cur.execute(prune_query, (before,))\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to prune completed tasks older than {before} seconds: {e}')\n            self.conn.rollback()"
        },
        {
            "key_id": 1,
            "fqn": "postgrestq/task_queue.py/TaskQueue/connect",
            "imports": [
                "import psycopg",
                "import logging"
            ],
            "code": "def connect(self) -> None:\n        try:\n            self.conn = psycopg.connect(self.dsn)\n            self.cur = self.conn.cursor()\n        except Exception as e:\n            self.logger.error(f'Failed to connect to the database: {e}')\n            raise"
        },
        {
            "key_id": 10,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_serialize",
            "imports": [
                "import json"
            ],
            "code": "def _serialize(self, task: Any) -> str:\n        return json.dumps(task)"
        },
        {
            "key_id": 11,
            "fqn": "postgrestq/task_queue.py/TaskQueue/_deserialize",
            "imports": [
                "import json"
            ],
            "code": "def _deserialize(self, blob: str) -> Any:\n        return json.loads(blob)"
        },
        {
            "key_id": 3,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__len__",
            "imports": [],
            "code": "def __len__(self) -> int:\n        count_query = f'SELECT COUNT(*) FROM {self.table_name} WHERE queue_name = %s AND completed_at IS NULL;'\n        self.cur.execute(count_query, (self.queue_name,))\n        count = self.cur.fetchone()[0]\n        return count"
        },
        {
            "key_id": 4,
            "fqn": "postgrestq/task_queue.py/TaskQueue/add",
            "imports": [
                "from uuid import uuid4"
            ],
            "code": "def add(self, task: Dict[str, Any], lease_timeout: float, ttl: int = 3) -> str:\n        task_id = str(uuid4())\n        serialized_task = self._serialize(task)\n        insert_query = f\"\"\"INSERT INTO {self.table_name} (id, queue_name, task, ttl, lease_timeout, processing, created_at)\n                         VALUES (%s, %s, %s, %s, %s, false, CURRENT_TIMESTAMP)\"\"\"\n        try:\n            self.cur.execute(insert_query, (task_id, self.queue_name, serialized_task, ttl, lease_timeout))\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to add task to queue {self.queue_name}: {e}')\n            self.conn.rollback()\n        return task_id"
        },
        {
            "key_id": 5,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get",
            "imports": [],
            "code": "def get(self) -> Tuple[Optional[Dict[str, Any]], Optional[UUID]]:\n        get_query = f\"\"\"UPDATE {self.table_name} SET processing = true, deadline = CURRENT_TIMESTAMP + (lease_timeout * INTERVAL '1 second')\n                      WHERE id = (SELECT id FROM {self.table_name} WHERE queue_name = %s AND processing = false AND completed_at IS NULL ORDER BY created_at FOR UPDATE SKIP LOCKED LIMIT 1)\n                      RETURNING id, task;\"\"\"\n        self.cur.execute(get_query, (self.queue_name,))\n        result = self.cur.fetchone()\n        if result:\n            task_id, task_blob = result\n            return self._deserialize(task_blob), task_id\n        return None, None"
        },
        {
            "key_id": 6,
            "fqn": "postgrestq/task_queue.py/TaskQueue/complete",
            "imports": [
                "import time"
            ],
            "code": "def complete(self, task_id: Optional[UUID]) -> None:\n        complete_query = f'UPDATE {self.table_name} SET completed_at = CURRENT_TIMESTAMP WHERE id = %s;'\n        try:\n            self.cur.execute(complete_query, (task_id,))\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to mark task {task_id} as complete: {e}')\n            self.conn.rollback()"
        },
        {
            "key_id": 7,
            "fqn": "postgrestq/task_queue.py/TaskQueue/is_empty",
            "imports": [],
            "code": "def is_empty(self) -> bool:\n        return self.__len__() == 0"
        },
        {
            "key_id": 8,
            "fqn": "postgrestq/task_queue.py/TaskQueue/check_expired_leases",
            "imports": [],
            "code": "def check_expired_leases(self) -> None:\n        check_query = f\"\"\"UPDATE {self.table_name} SET processing = false, deadline = NULL\n                          WHERE queue_name = %s AND processing = true AND deadline < CURRENT_TIMESTAMP;\"\"\"\n        try:\n            self.cur.execute(check_query, (self.queue_name,))\n            self.conn.commit()\n        except Exception as e:\n            self.logger.error(f'Failed to check and reset expired leases for queue {self.queue_name}: {e}')\n            self.conn.rollback()"
        },
        {
            "key_id": 9,
            "fqn": "postgrestq/task_queue.py/TaskQueue/get_updated_expired_task",
            "imports": [],
            "code": "def get_updated_expired_task(self, task_id: UUID) -> Tuple[Optional[str], Optional[int]]:\n        get_task_query = f'SELECT task, ttl FROM {self.table_name} WHERE id = %s;'\n        self.cur.execute(get_task_query, (task_id,))\n        result = self.cur.fetchone()\n        if result:\n            task_blob, ttl = result\n            return self._deserialize(task_blob), ttl\n        return None, None"
        },
        {
            "key_id": 12,
            "fqn": "postgrestq/task_queue.py/TaskQueue/reschedule",
            "imports": [],
            "code": "def reschedule(self, task_id: Optional[UUID]) -> None:\n        task, ttl = self.get_updated_expired_task(task_id)\n        if task is not None and ttl > 0:\n            update_query = f\"\"\"UPDATE {self.table_name} SET processing = false, ttl = ttl - 1, deadline = NULL\n                              WHERE id = %s;\"\"\"\n            try:\n                self.cur.execute(update_query, (task_id,))\n                self.conn.commit()\n            except Exception as e:\n                self.logger.error(f'Failed to reschedule task {task_id}: {e}')\n                self.conn.rollback()"
        },
        {
            "key_id": 15,
            "fqn": "postgrestq/task_queue.py/TaskQueue/__iter__",
            "imports": [],
            "code": "def __iter__(self) -> Iterator[Tuple[Optional[Dict[str, Any]], Optional[UUID]]]:\n        while not self.is_empty():\n            task, task_id = self.get()\n            if task is not None:\n                yield task, task_id\n                self.complete(task_id)"
        }
    ]
}